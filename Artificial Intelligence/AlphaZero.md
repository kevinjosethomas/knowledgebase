AlphaZero, successor of [[AlphaGo]], was a model developed by DeepMind which served as a generalized algorithm which could master multiple games without prior knowledge of the game. Once again, it was trained with [[Reinforcement Learning (RL)]] and played millions of games of Chess, Go, and Shogi. 

Besides the policy and value heads it inherited from AlphaGo, AlphaZero also uses [[Monte Carlo Tree Search (MCTS)]] (a form of [[Alpha-Beta Pruning]]) to look ahead at possible moves and evaluate the best possible outcomes. 

AlphaZero was trained entirely with self-play, and did not require any human data to achieve it's performance.